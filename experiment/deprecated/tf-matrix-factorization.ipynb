{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d903b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 01:19:13.404818: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c46a1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 100\n",
    "rank = 10\n",
    "num_items = 50\n",
    "user_bias=0.5\n",
    "item_bias=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d7a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02a80c28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 01:19:14.664506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.664809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.665055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.665293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.682045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.682352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.682584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.682814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.683037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.683250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.683461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.683672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.684235: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-05 01:19:14.960970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.961223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.961425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.961624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.961817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.961999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.962180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.962357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.962535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.962712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.962889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:14.963067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:15.989662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:15.989910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:15.990118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:15.990319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:15.990510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:15.990693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:15.990871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:15.991047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:15.991229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:15.991395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22286 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-01-05 01:19:15.991757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:15.991923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22286 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6\n",
      "2023-01-05 01:19:15.992198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:15.992361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22286 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:82:00.0, compute capability: 8.6\n",
      "2023-01-05 01:19:15.992627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 01:19:15.992789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22286 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't convert Python sequence with mixed types to Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the matrix factors from random normals with mean 0. W will\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# represent users and H will represent items.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m W \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruncated_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnum_users\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstddev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m H \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mtruncated_normal([rank, num_items], stddev\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# To the user matrix we add a bias column holding the bias of each user,\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# and another column of 1s to multiply the item bias by.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/TF2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/TF2/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't convert Python sequence with mixed types to Tensor."
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the matrix factors from random normals with mean 0. W will\n",
    "# represent users and H will represent items.\n",
    "W = tf.Variable(tf.random.truncated_normal([num_users, rank], stddev=0.2, mean=0), name=\"users\")\n",
    "H = tf.Variable(tf.random.truncated_normal([rank, num_items], stddev=0.2, mean=0), name=\"items\")\n",
    "\n",
    "# To the user matrix we add a bias column holding the bias of each user,\n",
    "# and another column of 1s to multiply the item bias by.\n",
    "W_plus_bias = tf.concat(1, [W, tf.convert_to_tensor(user_bias, dtype=float32, name=\"user_bias\"), tf.ones((num_users,1), dtype=float32, name=\"item_bias_ones\")])\n",
    "# To the item matrix we add a row of 1s to multiply the user bias by, and\n",
    "# a bias row holding the bias of each item.\n",
    "H_plus_bias = tf.concat(0, [H, tf.ones((1, num_items), name=\"user_bias_ones\", dtype=float32), tf.convert_to_tensor(item_bias, dtype=float32, name=\"item_bias\")])\n",
    "# Multiply the factors to get our result as a dense matrix\n",
    "result = tf.matmul(W_plus_bias, H_plus_bias)\n",
    "\n",
    "# Now we just want the values represented by the pairs of user and item\n",
    "# indices for which we had known ratings. Unfortunately TensorFlow does not\n",
    "# yet support numpy-like indexing of tensors. See the issue for this at\n",
    "# https://github.com/tensorflow/tensorflow/issues/206 The workaround here\n",
    "# came from https://github.com/tensorflow/tensorflow/issues/418 and is a\n",
    "# little esoteric but in numpy this would just be done as follows:\n",
    "# result_values = result[user_indices, item_indices]\n",
    "result_values = tf.gather(tf.reshape(result, [-1]), user_indices * tf.shape(result)[1] + item_indices, name=\"extract_training_ratings\")\n",
    "\n",
    "# Same thing for the validation set ratings.\n",
    "result_values_val = tf.gather(tf.reshape(result, [-1]), user_indices_val * tf.shape(result)[1] + item_indices_val, name=\"extract_validation_ratings\")\n",
    "\n",
    "# Calculate the difference between the predicted ratings and the actual\n",
    "# ratings. The predicted ratings are the values obtained form the matrix\n",
    "# multiplication with the mean rating added on.\n",
    "diff_op = tf.sub(tf.add(result_values, mean_rating, name=\"add_mean\"), rating_values, name=\"raw_training_error\")\n",
    "diff_op_val = tf.sub(tf.add(result_values_val, mean_rating, name=\"add_mean_val\"), rating_values_val, name=\"raw_validation_error\")\n",
    "\n",
    "with tf.name_scope(\"training_cost\") as scope:\n",
    "    base_cost = tf.reduce_sum(tf.square(diff_op, name=\"squared_difference\"), name=\"sum_squared_error\")\n",
    "    # Add regularization.\n",
    "    regularizer = tf.mul(tf.add(tf.reduce_sum(tf.square(W)), tf.reduce_sum(tf.square(H))), lda, name=\"regularize\")\n",
    "    cost = tf.div(tf.add(base_cost, regularizer), num_ratings * 2, name=\"average_error\")\n",
    "\n",
    "with tf.name_scope(\"validation_cost\") as scope:\n",
    "    cost_val = tf.div(tf.reduce_sum(tf.square(diff_op_val, name=\"squared_difference_val\"), name=\"sum_squared_error_val\"), num_ratings_val * 2, name=\"average_error\")\n",
    "\n",
    "# Use an exponentially decaying learning rate.\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(lr, global_step, 10000, 0.96, staircase=True)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    # Passing global_step to minimize() will increment it at each step so\n",
    "    # that the learning rate will be decayed at the specified intervals.\n",
    "    train_step = optimizer.minimize(cost, global_step=global_step)\n",
    "\n",
    "with tf.name_scope(\"training_accuracy\") as scope:\n",
    "  # Just measure the absolute difference against the threshold\n",
    "  # TODO: support percentage-based thresholds\n",
    "  good = tf.less(tf.abs(diff_op), threshold)\n",
    "\n",
    "  accuracy_tr = tf.div(tf.reduce_sum(tf.cast(good, tf.float32)), num_ratings)\n",
    "  accuracy_tr_summary = tf.scalar_summary(\"accuracy_tr\", accuracy_tr)\n",
    "\n",
    "with tf.name_scope(\"validation_accuracy\") as scope:\n",
    "  # Validation set accuracy:\n",
    "  good_val = tf.less(tf.abs(diff_op_val), threshold)\n",
    "  accuracy_val = tf.reduce_sum(tf.cast(good_val, tf.float32)) / num_ratings_val\n",
    "  accuracy_val_summary = tf.scalar_summary(\"accuracy_val\", accuracy_val)\n",
    "\n",
    "# Create a TensorFlow session and initialize variables.\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# Make sure summaries get written to the logs.\n",
    "summary_op = tf.merge_all_summaries()\n",
    "writer = tf.train.SummaryWriter(\"/tmp/recommender_logs\", sess.graph_def)\n",
    "\n",
    "# Run the graph and see how we're doing on every 500th iteration.\n",
    "for i in range(max_iter):\n",
    "    if i % 500 == 0:\n",
    "        res = sess.run([summary_op, accuracy_tr, accuracy_val, cost, cost_val])\n",
    "        summary_str = res[0]\n",
    "        acc_tr = res[1]\n",
    "        acc_val = res[2]\n",
    "        cost_ev = res[3]\n",
    "        cost_val_ev = res[4]\n",
    "        writer.add_summary(summary_str, i)\n",
    "        print(\"Training accuracy at step %s: %s\" % (i, acc_tr))\n",
    "        print(\"Validation accuracy at step %s: %s\" % (i, acc_val))\n",
    "        print(\"Training cost: %s\" % (cost_ev))\n",
    "        print(\"Validation cost: %s\" % (cost_val_ev))\n",
    "    else:\n",
    "        sess.run(train_step)\n",
    "\n",
    "with tf.name_scope(\"final_model\") as scope:\n",
    "    # At the end we want to get the final ratings matrix by adding the mean\n",
    "    # to the result matrix and doing any further processing required\n",
    "    add_mean_final = tf.add(result, mean_rating, name=\"add_mean_final\")\n",
    "    if result_processor == None:\n",
    "        final_matrix = add_mean_final\n",
    "    else:\n",
    "        final_matrix = result_processor(add_mean_final)\n",
    "    final_res = sess.run([final_matrix])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2101453d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
