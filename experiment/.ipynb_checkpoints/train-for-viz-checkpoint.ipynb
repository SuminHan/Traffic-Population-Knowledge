{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58865ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 15:29:32.407127: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, datetime, argparse, tqdm, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from os.path import join as pjoin\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efcb6c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import mymodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a963ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--file_traf', type = str, default = '../prepdata/traffic-volume-A-20180101-20190101.df')\n",
    "parser.add_argument('--file_coarse', type = str, default = '../prepdata/coarse_grained_lte.h5')\n",
    "parser.add_argument('--file_fine', type = str, default = '../prepdata/fine_grained_lte.h5')\n",
    "\n",
    "parser.add_argument('--model_name', type = str, default = 'MySample')\n",
    "parser.add_argument('--memo', type = str, default = '')\n",
    "parser.add_argument('--save_dir', default = 'test', help = 'save_dir')\n",
    "\n",
    "parser.add_argument('--train_ratio', type = float, default = 0.7,\n",
    "                    help = 'training set [default : 0.7]')\n",
    "parser.add_argument('--val_ratio', type = float, default = 0.1,\n",
    "                    help = 'validation set [default : 0.1]')\n",
    "parser.add_argument('--test_ratio', type = float, default = 0.2,\n",
    "                    help = 'testing set [default : 0.2]')\n",
    "# parser.add_argument('--cnn_size', type = int, default = 3)\n",
    "parser.add_argument('--P', type = int, default = 6)\n",
    "parser.add_argument('--Q', type = int, default = 1)\n",
    "parser.add_argument('--time_slot', type = int, default = 60, help = 'a time step is 60 mins')\n",
    "\n",
    "parser.add_argument('--eta', type = float, default = 0.01,\n",
    "                    help = 'weight of mmd')\n",
    "parser.add_argument('--L', type = int, default = 3,\n",
    "                    help = 'number of STAtt Blocks')\n",
    "# parser.add_argument('--LZ', type = int, default = 2,\n",
    "#                     help = 'number of Regional STAtt Blocks')\n",
    "parser.add_argument('--K', type = int, default = 8,\n",
    "                    help = 'number of attention heads')\n",
    "parser.add_argument('--d', type = int, default = 8,\n",
    "                    help = 'dims of each head attention outputs')\n",
    "parser.add_argument('--D', type = int, default = 64)\n",
    "parser.add_argument('--batch_size', type = int, default = 32,\n",
    "                    help = 'batch size')\n",
    "parser.add_argument('--max_epoch', type = int, default = 1000,\n",
    "                    help = 'epoch to run')\n",
    "parser.add_argument('--patience', type = int, default = 20,\n",
    "                    help = 'patience for early stop')\n",
    "parser.add_argument('--learning_rate', type=float, default = 0.001,\n",
    "                    help = 'initial learning rate')\n",
    "parser.add_argument('--decay_epoch', type=int, default = 5,\n",
    "                    help = 'decay epoch')\n",
    "\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "    \n",
    "args.test_name = args.memo + args.model_name\n",
    "\n",
    "args.model_checkpoint_dir = f'checkpoint/'\n",
    "args.model_checkpoint = os.path.join(args.model_checkpoint_dir, args.test_name)\n",
    "args.test_dir = f'test_exp/'\n",
    "\n",
    "if not os.path.isdir(args.model_checkpoint_dir):\n",
    "    os.makedirs(args.model_checkpoint_dir)\n",
    "if not os.path.isdir(args.test_dir):\n",
    "    os.makedirs(args.test_dir)\n",
    "\n",
    "\n",
    "# (trainX, trainZC, trainZF, trainTE, trainY, \n",
    "#             valX, valZC, valZF, valTE, valY, \n",
    "#             testX, testZC, testZF, testTE, testY, extdata) = utils.loadVolumeData2(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe00c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774e0135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "def loadVolumeAE(args):\n",
    "    #traf_df = pd.read_csv(args.filepath, index_col=0, parse_dates=True)\n",
    "    traf_df = pd.read_hdf(args.file_traf)\n",
    "    coarse_df = pd.read_hdf(args.file_coarse)\n",
    "    # coarse_zero = np.zeros((1, len(coarse_df.columns)), dtype=np.float32)\n",
    "    # coarse_diff = np.concatenate((coarse_zero, np.diff(coarse_df.values, axis=0)), 0)\n",
    "    # coarse_diff_df = pd.DataFrame(coarse_diff, columns=coarse_df.columns)\n",
    "    # coarse_diff_df.index = coarse_df.index\n",
    "    # coarse_df = coarse_diff_df\n",
    "\n",
    "    fine_df = pd.read_hdf(args.file_fine)\n",
    "    # fine_zero = np.zeros((1, len(fine_df.columns)), dtype=np.float32)\n",
    "    # fine_diff = np.concatenate((fine_zero, np.diff(fine_df.values, axis=0)), 0)\n",
    "    # fine_diff_df = pd.DataFrame(fine_diff, columns=fine_df.columns)\n",
    "    # fine_diff_df.index = fine_df.index\n",
    "    # fine_df = fine_diff_df\n",
    "    \n",
    "    traf_df = traf_df.iloc[:24*7*30]\n",
    "    coarse_df = coarse_df.iloc[:24*7*30]\n",
    "    fine_df = fine_df.iloc[:24*7*30]\n",
    "\n",
    "    sid_list = []\n",
    "    traf_vals = np.nan_to_num(traf_df.values.astype(np.float32))\n",
    "    for sid, val in enumerate(np.sum(traf_vals == 0, 0)):\n",
    "        if val < traf_vals.shape[0]*0.3:\n",
    "            sid_list.append(traf_df.columns[sid])\n",
    "            \n",
    "    \n",
    "    traf_df = traf_df[sid_list]\n",
    "    print('traf_df', len(sid_list), traf_df.shape)\n",
    "\n",
    "    extdata = dict()\n",
    "\n",
    "    Traffic = np.nan_to_num(traf_df.values.astype(np.float32))\n",
    "    # Traffic_fill = fill_missing(traf_df).values.astype(np.float32)\n",
    "    num_step, num_sensors = traf_df.shape; extdata['num_nodes'] = num_sensors\n",
    "    \n",
    "    # train/val/test \n",
    "    train_steps = round(args.train_ratio * num_step)\n",
    "    test_steps = round(args.test_ratio * num_step)\n",
    "    val_steps = num_step - train_steps - test_steps\n",
    "\n",
    "    \n",
    "    # train_fill = train_traf = Traffic_fill[: train_steps]\n",
    "    # val_fill = Traffic_fill[train_steps : train_steps + val_steps]\n",
    "    # test_fill = Traffic_fill[-test_steps :]\n",
    "\n",
    "\n",
    "    Traffic = np.nan_to_num(traf_df.values.astype(np.float32))\n",
    "    train = Traffic[: train_steps]\n",
    "    val = Traffic[train_steps : train_steps + val_steps]\n",
    "    test = Traffic[-test_steps :]\n",
    "    \n",
    "    trainX, trainY = seq2instance(train, args.P, args.Q)\n",
    "    valX, valY = seq2instance(val, args.P, args.Q)\n",
    "    testX, testY = seq2instance(test, args.P, args.Q)\n",
    "    # normalization\n",
    "    maxval = np.max(train) + 1; extdata['maxval'] = maxval \n",
    "    trainX = trainX / maxval\n",
    "    valX = valX / maxval\n",
    "    testX = testX / maxval\n",
    "    \n",
    "    \n",
    "    CoarseLTE = np.nan_to_num(coarse_df.values.astype(np.float32))\n",
    "    CH, CW = coarse_df.columns[-1].split(','); CH = int(CH)+1; CW = int(CW)+1; \n",
    "    extdata['CH'] = CH; extdata['CW'] = CW\n",
    "    CoarseLTE = CoarseLTE.reshape(-1, CH, CW)\n",
    "\n",
    "    train = CoarseLTE[: train_steps]\n",
    "    val = CoarseLTE[train_steps : train_steps + val_steps]\n",
    "    test = CoarseLTE[-test_steps :]\n",
    "\n",
    "\n",
    "    # X, Y \n",
    "    trainZC, _ = seq2instance(train, args.P, args.Q)\n",
    "    valZC, _ = seq2instance(val, args.P, args.Q)\n",
    "    testZC, _ = seq2instance(test, args.P, args.Q)\n",
    "    # normalization\n",
    "    maxvalZC = np.max(train) + 1; extdata['maxvalZC'] = maxvalZC\n",
    "    trainZC = trainZC / maxvalZC\n",
    "    valZC = valZC / maxvalZC\n",
    "    testZC = testZC / maxvalZC\n",
    "\n",
    "    \n",
    "    # fine train/val/test\n",
    "    FineLTE = np.nan_to_num(fine_df.values.astype(np.float32))\n",
    "    FH, FW = fine_df.columns[-1].split(','); FH = int(FH)+1; FW = int(FW)+1\n",
    "    extdata['FH'] = FH; extdata['FW'] = FW\n",
    "    FineLTE = FineLTE.reshape(-1, FH, FW)\n",
    "    \n",
    "    train = FineLTE[: train_steps]\n",
    "    val = FineLTE[train_steps : train_steps + val_steps]\n",
    "    test = FineLTE[-test_steps :]\n",
    "\n",
    "    # X, Y \n",
    "    trainZF, _ = seq2instance(train, args.P, args.Q)\n",
    "    valZF, _ = seq2instance(val, args.P, args.Q)\n",
    "    testZF, _ = seq2instance(test, args.P, args.Q)\n",
    "    # normalization\n",
    "    maxvalZF = np.max(train) + 1; extdata['maxvalZF'] = maxvalZF\n",
    "    trainZF = trainZF / maxvalZF\n",
    "    valZF = valZF / maxvalZF\n",
    "    testZF = testZF / maxvalZF\n",
    "    \n",
    "    # temporal embedding \n",
    "    Time = traf_df.index\n",
    "    dayofweek =  np.reshape(Time.weekday, newshape = (-1, 1))\n",
    "    timeofday = (Time.hour * 3600 + Time.minute * 60 + Time.second) \\\n",
    "                // (args.time_slot*60) #// Time.freq.delta.total_seconds()\n",
    "    timeofday = np.reshape(timeofday, newshape = (-1, 1))    \n",
    "    Time = np.concatenate((dayofweek, timeofday), axis = -1)\n",
    "    # train/val/test\n",
    "    train = Time[: train_steps]\n",
    "    val = Time[train_steps : train_steps + val_steps]\n",
    "    test = Time[-test_steps :]\n",
    "    # shape = (num_sample, P + Q, 2)\n",
    "    trainTE = seq2instance(train, args.P, args.Q)\n",
    "    trainTE = np.concatenate(trainTE, axis = 1).astype(np.int32)\n",
    "    valTE = seq2instance(val, args.P, args.Q)\n",
    "    valTE = np.concatenate(valTE, axis = 1).astype(np.int32)\n",
    "    testTE = seq2instance(test, args.P, args.Q)\n",
    "    testTE = np.concatenate(testTE, axis = 1).astype(np.int32)\n",
    "\n",
    "    \n",
    "    return (trainX, trainZC, trainZF, trainTE, trainY, \n",
    "            valX, valZC, valZF, valTE, valY, \n",
    "            testX, testZC, testZF, testTE, testY, extdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c1a7ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traf_df 41 (5040, 41)\n"
     ]
    }
   ],
   "source": [
    "(trainX, trainZC, trainZF, trainTE, trainY, \n",
    "            valX, valZC, valZF, valTE, valY, \n",
    "            testX, testZC, testZF, testTE, testY, extdata) = loadVolumeAE(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10473e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_nodes': 41,\n",
       " 'maxval': 3430.0,\n",
       " 'CH': 31,\n",
       " 'CW': 38,\n",
       " 'maxvalZC': 138193.96875,\n",
       " 'FH': 30,\n",
       " 'FW': 33,\n",
       " 'maxvalZF': 60666.1640625}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e28a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from submodules import *\n",
    "\n",
    "def custom_mae_loss_inside(label, pred):\n",
    "    mask = tf.not_equal(label, 0)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    mask = tf.compat.v2.where(\n",
    "        condition = tf.math.is_nan(mask), x = 0., y = mask)\n",
    "    loss = tf.abs(tf.subtract(pred, label))\n",
    "    loss *= mask\n",
    "    loss = tf.compat.v2.where(\n",
    "        condition = tf.math.is_nan(loss), x = 0., y = loss)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "class BipartiteAttentionViz(tf.keras.layers.Layer):\n",
    "    def __init__(self, K, d):\n",
    "        super(BipartiteAttentionViz, self).__init__()\n",
    "        self.K = K\n",
    "        self.d = d\n",
    "        self.D = K*d\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.FC_Q = keras.Sequential([\n",
    "            layers.Dense(self.D, activation=\"relu\")])\n",
    "        self.FC_K = keras.Sequential([\n",
    "            layers.Dense(self.D, activation=\"relu\")])\n",
    "        self.FC_V = keras.Sequential([\n",
    "            layers.Dense(self.D, activation=\"relu\")])\n",
    "        self.FC_X = keras.Sequential([\n",
    "            layers.Dense(self.D, activation=\"relu\"),\n",
    "            layers.Dense(self.D)])\n",
    "        \n",
    "    def call(self, query, key, value):\n",
    "        K = self.K\n",
    "        d = self.d\n",
    "        D = self.D\n",
    "        \n",
    "        print(query.shape, key.shape, value.shape)\n",
    "        \n",
    "        query = self.FC_Q(query)\n",
    "        key = self.FC_K(key)\n",
    "        value = self.FC_V(value)\n",
    "\n",
    "        print('QKV', query.shape, key.shape, value.shape)\n",
    "    \n",
    "        query = tf.concat(tf.split(query, K, axis = -1), axis = 0)\n",
    "        key = tf.concat(tf.split(key, K, axis = -1), axis = 0)\n",
    "        value = tf.concat(tf.split(value, K, axis = -1), axis = 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # query = tf.transpose(query, perm = (0, 2, 1, 3))\n",
    "        # key = tf.transpose(key, perm = (0, 2, 3, 1))\n",
    "        # value = tf.transpose(value, perm = (0, 2, 1, 3))   \n",
    "    \n",
    "        attention = tf.matmul(query, key, transpose_b = True)\n",
    "        attention /= (d ** 0.5)\n",
    "        attention = tf.nn.softmax(attention, axis = -1)\n",
    "        \n",
    "        # [batch_size, num_step, N, D]\n",
    "        X = tf.matmul(attention, value)\n",
    "        #print('attention.shape, value.shape', attention.shape, value.shape, X.shape)\n",
    "        # X = tf.transpose(X, perm = (0, 2, 1, 3))\n",
    "        X = tf.concat(tf.split(X, K, axis = 0), axis = -1)\n",
    "        X = self.FC_X(X)\n",
    "        \n",
    "        return X, attention\n",
    "    \n",
    "class MySample(tf.keras.layers.Layer):\n",
    "    def __init__(self, extdata, args):\n",
    "        super(MySample, self).__init__()\n",
    "        self.D = args.D\n",
    "        self.K = args.K\n",
    "        self.d = args.d\n",
    "        self.L = args.L\n",
    "        self.num_nodes = extdata['num_nodes']\n",
    "        self.P = args.P\n",
    "        self.Q = args.Q\n",
    "        # self.SE = extdata['SE']\n",
    "        self.CH = extdata['CH']\n",
    "        self.CW = extdata['CW']\n",
    "        def cnn_dim(W):\n",
    "            W = (W-3)//2 + 1\n",
    "            W = (W-3)//2 + 1\n",
    "            return W\n",
    "        self.CNH = cnn_dim(self.CH)\n",
    "        self.CNW = cnn_dim(self.CW)\n",
    "        self.num_cells_C = cnn_dim(self.CH) * cnn_dim(self.CW)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        D = self.D\n",
    "        self.STE_layer = STEmbedding(self.num_nodes, D)\n",
    "        self.SE = self.add_weight(shape=(self.num_nodes, self.D),\n",
    "                                        initializer='glorot_uniform',\n",
    "                                        name='SE', dtype=tf.float32)\n",
    "        \n",
    "        self.GSTAC_enc = [GSTAttBlock(self.K, self.d) for _ in range(self.L)]\n",
    "        self.C_trans_layer = TransformAttention(self.K, self.d)\n",
    "        self.GSTAC_dec = [GSTAttBlock(self.K, self.d) for _ in range(self.L)]\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.FC_XC_in = keras.Sequential([\n",
    "                        layers.Dense(D, activation=\"relu\"),\n",
    "                        layers.Dense(D)])\n",
    "        \n",
    "        # self.FC_XC_out = keras.Sequential([\n",
    "        #                 layers.Dense(D, activation=\"relu\"),\n",
    "        #                 layers.Dense(1)])\n",
    "\n",
    "\n",
    "        ##################################\n",
    "        \n",
    "        self.STEZC_layer = STEmbedding(self.num_cells_C, D)\n",
    "        self.SEZC = self.add_weight(shape=(self.num_cells_C, D),\n",
    "                                        initializer='glorot_uniform',\n",
    "                                        name='SEZC', dtype=tf.float32)\n",
    "        self.FC_ZC_Conv = keras.Sequential([\n",
    "                                layers.Conv2D(D, 3, strides=(2, 2), padding='valid'),\n",
    "                                layers.BatchNormalization(),\n",
    "                                layers.LeakyReLU(),\n",
    "                                layers.Conv2D(D, 3, strides=(2, 2), padding='valid'),\n",
    "                                layers.BatchNormalization(),\n",
    "                            ])\n",
    "        self.RSTA_enc = GSTAttBlock(self.K, self.d)\n",
    "        self.XC_trans_layer = BipartiteAttentionViz(self.K, self.d)\n",
    "\n",
    "        self.GSTAC_enc2 = [GSTAttBlock(self.K, self.d) for _ in range(self.L)]\n",
    "        self.C_trans_layer2 = TransformAttention(self.K, self.d)\n",
    "        self.GSTAC_dec2 = [GSTAttBlock(self.K, self.d) for _ in range(self.L)]\n",
    "        # self.FC_XC_out2 = keras.Sequential([\n",
    "        #                 layers.Dense(D, activation=\"relu\"),\n",
    "        #                 layers.Dense(1)])\n",
    "        self.FC_XM = keras.Sequential([\n",
    "                            layers.Dense(D, activation=\"relu\"),\n",
    "                            layers.Dense(1)])\n",
    "        self.gated_fusion = GatedFusion(self.D)\n",
    "        self.FC_final = keras.Sequential([\n",
    "                            layers.Dense(D, activation=\"relu\"),\n",
    "                            layers.Dense(1)], name='FC_final')\n",
    "\n",
    "        \n",
    "    def call(self, X, ZC, ZF, TE):\n",
    "        X0 = X\n",
    "        TE = tf.cast(TE, tf.int32)\n",
    "        mask = tf.not_equal(X0, 0)\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "        \n",
    "        STE = self.STE_layer(self.SE, TE)\n",
    "        STEX_P, STEX_Q = STE[:, :self.P, :], STE[:, self.P:, :]\n",
    "\n",
    "        X = tf.expand_dims(X0, -1)\n",
    "        X = self.FC_XC_in(X) \n",
    "        for i in range(self.L):\n",
    "            X = self.GSTAC_enc[i](X, STEX_P)\n",
    "        X = self.C_trans_layer(X, STEX_P, STEX_Q)\n",
    "        for i in range(self.L):\n",
    "            X = self.GSTAC_dec[i](X, STEX_Q)\n",
    "        YY1 = X\n",
    "        # X = self.FC_XC_out(X)\n",
    "        # Y1 = tf.squeeze(X, -1)\n",
    "\n",
    "        ###############################\n",
    "        STEZ = self.STEZC_layer(self.SEZC, TE)\n",
    "        STEZ_P, STEZ_Q = STEZ[:, :self.P, :], STEZ[:, self.P:, :]\n",
    "\n",
    "        if len(ZC.shape) == 4:\n",
    "            ZC = tf.expand_dims(ZC, -1)\n",
    "        ZC = self.FC_ZC_Conv(ZC)\n",
    "        ZC = tf.reshape(ZC, (-1, self.P, ZC.shape[2]*ZC.shape[3], self.D))\n",
    "\n",
    "        ZC = self.RSTA_enc(ZC, STEZ_P)\n",
    "        \n",
    "        ZX, attention = self.XC_trans_layer(STEX_P, STEZ_P, ZC)\n",
    "\n",
    "        X_gen = self.FC_XM(ZX)[..., 0]\n",
    "        X = mask*X0 + (1-mask)*X_gen\n",
    "        custom_loss = 0*custom_mae_loss_inside(X0, X_gen)\n",
    "        self.add_loss(custom_loss)\n",
    "\n",
    "        for i in range(self.L):\n",
    "            ZX = self.GSTAC_enc2[i](ZX, STEX_P)\n",
    "        ZX = self.C_trans_layer2(ZX, STEX_P, STEX_Q)\n",
    "        for i in range(self.L):\n",
    "            ZX = self.GSTAC_dec2[i](ZX, STEX_Q)\n",
    "        YY2 = ZX\n",
    "        # ZX = self.FC_XC_out2(ZX)\n",
    "        # Y2 = tf.squeeze(ZX, -1)\n",
    "\n",
    "        # Y = Y1 + Y2\n",
    "\n",
    "        \n",
    "        Y = self.FC_final(self.gated_fusion(YY1, YY2))\n",
    "        Y = tf.squeeze(Y, -1)\n",
    "\n",
    "\n",
    "        return Y, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b823dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 15:29:34.276731: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:29:34.295064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:29:34.295364: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:29:34.296129: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 15:29:34.298294: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:29:34.298537: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:29:34.298761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:29:34.675751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:29:34.676017: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:29:34.676239: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:29:34.676428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22282 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE (41, 64) TE (None, 7, 2)\n",
      "SE (56, 64) TE (None, 7, 2)\n",
      "(None, 6, 41, 64) (None, 6, 56, 64) (None, 6, 56, 64)\n",
      "QKV (None, 6, 41, 64) (None, 6, 56, 64) (None, 6, 56, 64)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 6, 41)]      0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 6, 31, 38)]  0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 6, 30, 33)]  0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 7, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " my_sample (MySample)           ((None, 1, 41),      1227522     ['input_1[0][0]',                \n",
      "                                 (None, 6, 41, 56))               'input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]',                \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 1, 41)        0           ['my_sample[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,227,522\n",
      "Trainable params: 1,225,602\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model_define():\n",
    "    X = layers.Input(shape=trainX.shape[1:], dtype=tf.float32)\n",
    "    ZC = layers.Input(shape=trainZC.shape[1:], dtype=tf.float32)\n",
    "    ZF = layers.Input(shape=trainZF.shape[1:], dtype=tf.float32)\n",
    "    TE = layers.Input(shape=trainTE.shape[1:], dtype=tf.int32) # int32\n",
    "    \n",
    "    model = MySample(extdata, args)\n",
    "    Y, attention = model(X, ZC, ZF, TE)\n",
    "    \n",
    "    Y = Y * extdata['maxval']\n",
    "    model = keras.models.Model((X, ZC, ZF, TE), Y)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = model_define()\n",
    "# model.load_weights(args.model_checkpoint).expect_partial()\n",
    "model.summary()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e573ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "SE (41, 64) TE (None, 7, 2)\n",
      "SE (56, 64) TE (None, 7, 2)\n",
      "(None, 6, 41, 64) (None, 6, 56, 64) (None, 6, 56, 64)\n",
      "QKV (None, 6, 41, 64) (None, 6, 56, 64) (None, 6, 56, 64)\n",
      "SE (41, 64) TE (None, 7, 2)\n",
      "SE (56, 64) TE (None, 7, 2)\n",
      "(None, 6, 41, 64) (None, 6, 56, 64) (None, 6, 56, 64)\n",
      "QKV (None, 6, 41, 64) (None, 6, 56, 64) (None, 6, 56, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 15:30:08.940743: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n",
      "2023-02-27 15:30:09.792687: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-02-27 15:30:09.870367: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x55f6e57f4a10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-27 15:30:09.870400: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-02-27 15:30:09.875245: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-27 15:30:09.958901: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - ETA: 0s - loss: 225.9978SE (41, 64) TE (None, 7, 2)\n",
      "SE (56, 64) TE (None, 7, 2)\n",
      "(None, 6, 41, 64) (None, 6, 56, 64) (None, 6, 56, 64)\n",
      "QKV (None, 6, 41, 64) (None, 6, 56, 64) (None, 6, 56, 64)\n",
      "111/111 [==============================] - 62s 116ms/step - loss: 225.9978 - val_loss: 521.6400 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "111/111 [==============================] - 9s 78ms/step - loss: 133.7291 - val_loss: 450.4788 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "111/111 [==============================] - 9s 78ms/step - loss: 98.6535 - val_loss: 383.5780 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "111/111 [==============================] - 9s 77ms/step - loss: 87.3631 - val_loss: 295.2758 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "111/111 [==============================] - 9s 78ms/step - loss: 79.4136 - val_loss: 196.2164 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "111/111 [==============================] - 9s 81ms/step - loss: 71.8800 - val_loss: 126.3213 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "111/111 [==============================] - 9s 78ms/step - loss: 70.4743 - val_loss: 99.9896 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "111/111 [==============================] - 8s 72ms/step - loss: 70.1972 - val_loss: 114.7726 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "111/111 [==============================] - 9s 78ms/step - loss: 70.7995 - val_loss: 94.4299 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      " 70/111 [=================>............] - ETA: 2s - loss: 65.0635"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def custom_mae_loss(label, pred):\n",
    "    mask = tf.not_equal(label, 0)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    mask = tf.compat.v2.where(\n",
    "        condition = tf.math.is_nan(mask), x = 0., y = mask)\n",
    "    loss = tf.abs(tf.subtract(pred, label))\n",
    "    loss *= mask\n",
    "    loss = tf.compat.v2.where(\n",
    "        condition = tf.math.is_nan(loss), x = 0., y = loss)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss\n",
    "\n",
    "model.compile(loss=custom_mae_loss, optimizer=optimizer)\n",
    "\n",
    "# Define some callbacks to improve training.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=args.patience)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=args.decay_epoch)\n",
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = args.model_checkpoint,\n",
    "    monitor = 'val_loss',\n",
    "    verbose = 0,\n",
    "    save_best_only = True,\n",
    "    save_weights_only = True,\n",
    "    cooldown=3,\n",
    "    mode = 'auto',\n",
    "    save_freq='epoch',\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    (trainX, trainZC, trainZF, trainTE), trainY,\n",
    "    batch_size=args.batch_size,\n",
    "    epochs=args.max_epoch,\n",
    "    validation_data=((valX, valZC, valZF, valTE), valY),\n",
    "    callbacks=[early_stopping, reduce_lr, model_ckpt],\n",
    "    # callbacks=[early_stopping, model_ckpt],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa3cce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.get_layer('my_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eb16dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE (41, 64) TE (3522, 7, 2)\n",
      "SE (56, 64) TE (3522, 7, 2)\n",
      "(3522, 6, 41, 64) (3522, 6, 56, 64) (3522, 6, 56, 64)\n",
      "QKV (3522, 6, 41, 64) (3522, 6, 56, 64) (3522, 6, 56, 64)\n"
     ]
    }
   ],
   "source": [
    "predY, attention = layer(trainX, trainZC, trainZF, trainTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8af91224",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = attention.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fca0411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = att.reshape(predY.shape[0], 8, 6, attention.shape[2], attention.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7c53bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "01624b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efaa7427b50>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 548.571x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# batch#, attention head, time sequence, sensor#, region#\n",
    "plt.matshow(att[0, 0, -1, 31, :].reshape(layer.CNH, layer.CNW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6232d336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dbb893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ec658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a9ac7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf8fb26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bade555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ecebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc0fca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d384eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
